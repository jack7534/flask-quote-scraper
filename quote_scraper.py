import requests
from bs4 import BeautifulSoup
import json
import re
import math  # ğŸ”¹ å¼•å…¥ math æ¨¡çµ„ä¾†è™•ç†ç„¡æ¢ä»¶é€²ä½

# è¨­å®š User-Agent é¿å…è¢«æ“‹
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

def clean_price(price_text):
    """ æ¸…ç†åƒ¹æ ¼å­—ä¸²ï¼Œç¢ºä¿èƒ½è½‰æ›ç‚º int """
    price_text = price_text.replace("å††", "").replace(",", "").replace("(ç¨è¾¼)", "").replace("(ç¨ 0)", "").strip()
    return int(re.sub(r"[^\d]", "", price_text))  # åªä¿ç•™æ•¸å­—éƒ¨åˆ†ï¼Œç§»é™¤æ—¥æ–‡å­—

def scrape_amazon_japan(url):
    """ çˆ¬å– Amazon Japan å•†å“è³‡è¨Š """
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.text, "lxml")

        title = soup.select_one("#productTitle")
        price = soup.select_one(".a-price .a-offscreen")

        if title and price:
            price_jpy = clean_price(price.text)
            return {
                "ç¶²ç«™": "Amazon Japan",
                "åç¨±": title.text.strip(),
                "æ—¥å¹£åƒ¹æ ¼": price_jpy,
                "å°å¹£å ±åƒ¹": math.ceil(price_jpy * 0.35),  # ğŸ”¹ ç„¡æ¢ä»¶é€²ä½
                "é€£çµ": url
            }
        return None
    except Exception as e:
        return {"éŒ¯èª¤": f"Amazon çˆ¬å–å¤±æ•—: {str(e)}"}

def scrape_rakuten(url):
    """ çˆ¬å– Rakuten æ¨‚å¤©å¸‚å ´ å•†å“è³‡è¨Š """
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.text, "lxml")

        # **1ï¸âƒ£ ç²å–å•†å“åç¨±**
        title = soup.select_one(".item-name") or soup.select_one("h1") or soup.select_one("meta[property='og:title']")
        if title and title.name == "meta":
            title_text = title["content"].strip()
        elif title:
            title_text = title.text.strip()
        else:
            title_text = "ç„¡æ³•ç²å–å•†å“åç¨±"

        # **2ï¸âƒ£ æŠ“å–åƒ¹æ ¼**
        price_jpy = None

        # **å¾ `<meta itemprop="price">` å…§ç²å–åƒ¹æ ¼**
        meta_element = soup.select_one("meta[itemprop='price']")
        if meta_element and "content" in meta_element.attrs:
            price_jpy = int(meta_element["content"])

        # **å˜—è©¦å¾ `#priceCalculationConfig` æŠ“ `data-price`**
        if not price_jpy:
            config_element = soup.select_one("#priceCalculationConfig")
            if config_element and "data-price" in config_element.attrs:
                price_jpy = int(config_element["data-price"])

        # **å˜—è©¦å¾ `<input id="ratPrice">` å…§æŠ“åƒ¹æ ¼**
        if not price_jpy:
            input_element = soup.select_one("input#ratPrice")
            if input_element and "value" in input_element.attrs:
                price_jpy = int(input_element["value"])

        # **Debug: æ‰“å°æ‰¾åˆ°çš„åƒ¹æ ¼èˆ‡åç¨±**
        print(f"ğŸ’¡ æ¨‚å¤©åƒ¹æ ¼è§£æï¼šåƒ¹æ ¼={price_jpy}")
        print(f"ğŸ›’ æ¨‚å¤©å•†å“åç¨±ï¼š{title_text}")

        # **å›å‚³çµæœ**
        if price_jpy:
            return {
                "ç¶²ç«™": "Rakuten",
                "åç¨±": title_text,
                "æ—¥å¹£åƒ¹æ ¼": price_jpy,
                "å°å¹£å ±åƒ¹": math.ceil(price_jpy * 0.35),  # ğŸ”¹ ç„¡æ¢ä»¶é€²ä½
                "é€£çµ": url
            }
        else:
            return {"éŒ¯èª¤": "ç„¡æ³•ç²å–æ¨‚å¤©å¸‚å ´åƒ¹æ ¼"}

    except Exception as e:
        return {"éŒ¯èª¤": f"Rakuten çˆ¬å–å¤±æ•—: {str(e)}"}

def scrape_yahoo_auction(url):
    """ çˆ¬å– Yahoo Auctions å•†å“è³‡è¨Š """
    try:
        response = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.text, "lxml")

        # æŠ“å–å•†å“åç¨±
        title = soup.select_one(".Product__title") or soup.select_one(".ProductTitle__text")

        # å˜—è©¦ç²å–ç«¶æ¨™åƒ¹æˆ–ç›´è³¼åƒ¹
        bid_price = soup.select_one(".Price__value")  # ç«¶æ¨™åƒ¹
        buy_price = soup.select_one(".Price__now") or soup.select_one(".ProductPrice__value")  # ç›´è³¼åƒ¹
        auction_time = soup.select_one(".Auction__endTime")  # ç«¶æ¨™çµæŸæ™‚é–“

        price_jpy = None
        price_text = None

        # **å˜—è©¦æŠ“å–åƒ¹æ ¼ï¼Œå„ªå…ˆç›´è³¼åƒ¹**
        if buy_price:
            price_text = buy_price.text.strip()
        elif bid_price:
            price_text = bid_price.text.strip()

        # **ç¢ºä¿æ•¸å€¼ä¸è¢« `ç¨ 0 å††` å½±éŸ¿**
        if price_text:
            price_text = re.sub(r"ç¨\s*\d*\s*å††", "", price_text)  # ç§»é™¤ç¨å‹™è¨Šæ¯
            price_jpy = int(re.sub(r"[^\d]", "", price_text))  # åªä¿ç•™æ•¸å­—

        # **çµæœæ•´ç†**
        if title and price_jpy:
            return {
                "ç¶²ç«™": "Yahoo Auctions",
                "åç¨±": title.text.strip(),
                "æ—¥å¹£åƒ¹æ ¼": price_jpy,
                "å°å¹£å ±åƒ¹": math.ceil(price_jpy * 0.35),  # ğŸ”¹ ç„¡æ¢ä»¶é€²ä½
                "ç«¶æ¨™çµæŸæ™‚é–“": auction_time.text.strip() if auction_time else "ç„¡æ³•å–å¾—",
                "é€£çµ": url
            }
        return {"éŒ¯èª¤": "ç„¡æ³•ç²å– Yahoo Auctions åƒ¹æ ¼"}

    except Exception as e:
        return {"éŒ¯èª¤": f"Yahoo Auctions çˆ¬å–å¤±æ•—: {str(e)}"}

def get_quotation(url):
    """ æ ¹æ“šæä¾›çš„ç¶²å€ï¼Œé¸æ“‡å°æ‡‰çš„çˆ¬èŸ² """
    if "amazon.co.jp" in url:
        return scrape_amazon_japan(url)
    elif "rakuten.co.jp" in url:
        return scrape_rakuten(url)
    elif "auctions.yahoo.co.jp" in url:
        return scrape_yahoo_auction(url)
    else:
        return {"éŒ¯èª¤": "ç›®å‰ä¸æ”¯æ´æ­¤ç¶²ç«™"}

if __name__ == "__main__":
    print("\nğŸ“Œ **è«‹å…ˆå‰å¾€ä»¥ä¸‹ç¶²ç«™æœå°‹å•†å“ï¼Œç„¶å¾Œè¤‡è£½å•†å“ç¶²å€è²¼ä¸ŠæŸ¥è©¢å ±åƒ¹ï¼š**")
    print("ğŸ”¹ [Amazon Japan](https://www.amazon.co.jp/)")
    print("ğŸ”¹ [Rakuten æ¨‚å¤©å¸‚å ´](https://search.rakuten.co.jp/)")
    print("ğŸ”¹ [Yahoo Auctions é›…è™æ‹è³£](https://auctions.yahoo.co.jp/)\n")

    url = input("ğŸ” è«‹è¼¸å…¥å•†å“ç¶²å€ï¼š")
    result = get_quotation(url)

    if result is None:
        print("âŒ ç„¡æ³•ç²å–è©²å•†å“çš„è³‡è¨Šï¼Œè«‹ç¢ºèªç¶²å€æ˜¯å¦æ­£ç¢º")
    elif "éŒ¯èª¤" in result:
        print(f"âŒ {result['éŒ¯èª¤']}")
    else:
        print("\nğŸ“Œ å ±åƒ¹çµæœï¼š")
        print(f"ğŸ›’ ç¶²ç«™ï¼š{result['ç¶²ç«™']}")
        print(f"ğŸ“Œ å•†å“åç¨±ï¼š{result['åç¨±']}")
        print(f"ğŸ’´ åŸåƒ¹ï¼ˆæ—¥å¹£ï¼‰ï¼šÂ¥{result['æ—¥å¹£åƒ¹æ ¼']}")
        print(f"ğŸ’° å°å¹£å ±åƒ¹ï¼šNT$ {result['å°å¹£å ±åƒ¹']}")
        if "ç«¶æ¨™çµæŸæ™‚é–“" in result:
            print(f"â³ ç«¶æ¨™çµæŸæ™‚é–“ï¼š{result['ç«¶æ¨™çµæŸæ™‚é–“']}")
        print(f"ğŸ”— å•†å“é€£çµï¼š{result['é€£çµ']}\n")
