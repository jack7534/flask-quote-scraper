import requests
from bs4 import BeautifulSoup
import json
import re
import math
import time  # âœ… åŠ å…¥ time.sleep ä¾†é˜²æ­¢éå¿«è«‹æ±‚è¢«å°é–

# è¨­å®š User-Agent é¿å…è¢«æ“‹
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

def clean_price(price_text):
    """ æ¸…ç†åƒ¹æ ¼å­—ä¸²ï¼Œç¢ºä¿èƒ½è½‰æ›ç‚º int """
    price_text = price_text.replace("å††", "").replace(",", "").replace("(ç¨è¾¼)", "").replace("(ç¨ 0)", "").strip()
    return int(re.sub(r"[^\d]", "", price_text))  # åªä¿ç•™æ•¸å­—éƒ¨åˆ†ï¼Œç§»é™¤æ—¥æ–‡å­—

def scrape_amazon_japan(url):
    """ çˆ¬å– Amazon Japan å•†å“è³‡è¨Š """
    try:
        time.sleep(2)  # âœ… é˜²æ­¢è«‹æ±‚éå¿«
        response = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.text, "lxml")

        title = soup.select_one("#productTitle")
        price = soup.select_one(".a-price .a-offscreen")

        if title and price:
            price_jpy = clean_price(price.text)
            return {
                "ç¶²ç«™": "Amazon Japan",
                "åç¨±": title.text.strip(),
                "æ—¥å¹£åƒ¹æ ¼": price_jpy,
                "å°å¹£å ±åƒ¹": math.ceil(price_jpy * 0.35),
                "é€£çµ": url
            }
        return {"éŒ¯èª¤": "ç„¡æ³•ç²å– Amazon å•†å“åƒ¹æ ¼"}
    except Exception as e:
        return {"éŒ¯èª¤": f"Amazon çˆ¬å–å¤±æ•—: {str(e)}"}

def scrape_rakuten(url):
    """ çˆ¬å– Rakuten æ¨‚å¤©å¸‚å ´ å•†å“è³‡è¨Š """
    try:
        time.sleep(2)  # âœ… é˜²æ­¢è«‹æ±‚éå¿«
        response = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.text, "lxml")

        title = soup.select_one(".item-name") or soup.select_one("h1") or soup.select_one("meta[property='og:title']")
        if title and title.name == "meta":
            title_text = title["content"].strip()
        elif title:
            title_text = title.text.strip()
        else:
            title_text = "ç„¡æ³•ç²å–å•†å“åç¨±"

        # å˜—è©¦ä¸åŒçš„æ–¹æ³•ç²å–åƒ¹æ ¼
        price_jpy = None
        price_elements = [
            soup.select_one("meta[itemprop='price']"),
            soup.select_one("#priceCalculationConfig"),
            soup.select_one("input#ratPrice"),
            soup.select_one(".price")  # âœ… æ–°å¢é¸æ“‡å™¨
        ]

        for element in price_elements:
            if element and element.has_attr("content"):
                price_jpy = clean_price(element["content"])
                break
            elif element and element.has_attr("data-price"):
                price_jpy = clean_price(element["data-price"])
                break
            elif element:
                price_jpy = clean_price(element.text)
                break

        if price_jpy:
            return {
                "ç¶²ç«™": "Rakuten",
                "åç¨±": title_text,
                "æ—¥å¹£åƒ¹æ ¼": price_jpy,
                "å°å¹£å ±åƒ¹": math.ceil(price_jpy * 0.35),
                "é€£çµ": url
            }
        else:
            return {"éŒ¯èª¤": "ç„¡æ³•ç²å– Rakuten å•†å“åƒ¹æ ¼"}

    except Exception as e:
        return {"éŒ¯èª¤": f"Rakuten çˆ¬å–å¤±æ•—: {str(e)}"}

def scrape_yahoo_auction(url):
    """ çˆ¬å– Yahoo Auctions å•†å“è³‡è¨Š """
    try:
        time.sleep(2)  # âœ… é˜²æ­¢è«‹æ±‚éå¿«
        response = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(response.text, "lxml")

        title = soup.select_one(".Product__title") or soup.select_one(".ProductTitle__text")

        bid_price = soup.select_one(".Price__value")
        buy_price = soup.select_one(".Price__now") or soup.select_one(".ProductPrice__value")
        auction_time = soup.select_one(".Auction__endTime")

        price_jpy = None
        price_text = None

        if buy_price:
            price_text = buy_price.text.strip()
        elif bid_price:
            price_text = bid_price.text.strip()

        if price_text:
            price_text = re.sub(r"ç¨\s*\d*\s*å††", "", price_text)
            price_jpy = int(re.sub(r"[^\d]", "", price_text))

        if price_jpy:
            return {
                "ç¶²ç«™": "Yahoo Auctions",
                "åç¨±": title.text.strip() if title else "ç„¡æ³•ç²å–å•†å“åç¨±",
                "æ—¥å¹£åƒ¹æ ¼": price_jpy,
                "å°å¹£å ±åƒ¹": math.ceil(price_jpy * 0.35),
                "ç«¶æ¨™çµæŸæ™‚é–“": auction_time.text.strip() if auction_time else "ç„¡æ³•å–å¾—",
                "é€£çµ": url
            }
        return {"éŒ¯èª¤": "ç„¡æ³•ç²å– Yahoo Auctions åƒ¹æ ¼"}

    except Exception as e:
        return {"éŒ¯èª¤": f"Yahoo Auctions çˆ¬å–å¤±æ•—: {str(e)}"}

def get_quotation(url):
    """ æ ¹æ“šæä¾›çš„ç¶²å€ï¼Œé¸æ“‡å°æ‡‰çš„çˆ¬èŸ² """
    if "amazon.co.jp" in url:
        return scrape_amazon_japan(url)
    elif "rakuten.co.jp" in url:
        return scrape_rakuten(url)
    elif "auctions.yahoo.co.jp" in url:
        return scrape_yahoo_auction(url)
    else:
        return {"éŒ¯èª¤": "ç›®å‰ä¸æ”¯æ´æ­¤ç¶²ç«™"}

if __name__ == "__main__":
    print("\nğŸ“Œ **è«‹å…ˆå‰å¾€ä»¥ä¸‹ç¶²ç«™æœå°‹å•†å“ï¼Œç„¶å¾Œè¤‡è£½å•†å“ç¶²å€è²¼ä¸ŠæŸ¥è©¢å ±åƒ¹ï¼š**")
    print("ğŸ”¹ [Amazon Japan](https://www.amazon.co.jp/)")
    print("ğŸ”¹ [Rakuten æ¨‚å¤©å¸‚å ´](https://search.rakuten.co.jp/)")
    print("ğŸ”¹ [Yahoo Auctions é›…è™æ‹è³£](https://auctions.yahoo.co.jp/)\n")

    url = input("ğŸ” è«‹è¼¸å…¥å•†å“ç¶²å€ï¼š")
    result = get_quotation(url)

    if result is None:
        print("âŒ ç„¡æ³•ç²å–è©²å•†å“çš„è³‡è¨Šï¼Œè«‹ç¢ºèªç¶²å€æ˜¯å¦æ­£ç¢º")
    elif "éŒ¯èª¤" in result:
        print(f"âŒ {result['éŒ¯èª¤']}")
    else:
        print("\nğŸ“Œ å ±åƒ¹çµæœï¼š")
        print(f"ğŸ›’ ç¶²ç«™ï¼š{result['ç¶²ç«™']}")
        print(f"ğŸ“Œ å•†å“åç¨±ï¼š{result['åç¨±']}")
        print(f"ğŸ’´ åŸåƒ¹ï¼ˆæ—¥å¹£ï¼‰ï¼šÂ¥{result['æ—¥å¹£åƒ¹æ ¼']}")
        print(f"ğŸ’° å°å¹£å ±åƒ¹ï¼šNT$ {result['å°å¹£å ±åƒ¹']}")
        if "ç«¶æ¨™çµæŸæ™‚é–“" in result:
            print(f"â³ ç«¶æ¨™çµæŸæ™‚é–“ï¼š{result['ç«¶æ¨™çµæŸæ™‚é–“']}")
        print(f"ğŸ”— å•†å“é€£çµï¼š{result['é€£çµ']}\n")
